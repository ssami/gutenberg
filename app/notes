# Redis: ~/Git_personal/MachineLearning/gutenberg/redis-stable/src/redis-server
# Minio: [start Docker] docker run -p 9000:9000 -e "MINIO_ACCESS_KEY=admin" -e "MINIO_SECRET_KEY=password" minio/minio server /data
##
# Couchbase:
# username: admin
# password: password
# docker run -d --name db -p 8091-8096:8091-8096 -p 11210-11211:11210-11211 couchbase

# cbbackup http://localhost:8091 -u admin -p password /backup
# cbrestore /2018-10-08T052813Z/2018-10-08T052813Z-full/ http://localhost:8091 --bucket-source=feedback --bucket-destination=feedback -u admin -p password


Now that we have set up Spark with Docker and are able to run some PySpark examples on it, we can even move the original training data into the Spark container.
However, that leaves us with a different problem, which is -- what to do with the feedback data? It needs to be moved into the Spark environment for us to really use it to train.

root@dac9157d87a8:/# couchbase-server -v
Couchbase Server 5.5.2-3733 (EE)

Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.3.1
      /_/

Using Python version 3.5.3 (default, Jan 19 2017 14:11:04)

Spark 2.3.x + Couchbase 5.5 = Connector 2.2.x
This is great, but right now there's only support for Scala and it will be hard to get this to work with CouchBase in PySpark. Here are some examples: https://github.com/couchbaselabs/couchbase-spark-samples/blob/master/src/main/scala/DatasetExample.scala.
This would be a great project to undertake when we're more comfortable with Scala and can move the Python training code into Scala.

For now, let's use Scikit Learn and Pipelines to re-train with the original data + feedback.
http://fizzylogic.nl/2017/11/07/learn-how-to-build-flexible-machine-learning-pipelines-in-sklearn/

It turns out that for Scikit you can write your own custom estimator (maybe we can also do a good grid search!) http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/

This seems simple enough. But why do you need to implement the "fit" method? It's not even in the BaseEstimator or the ClassifierMixin.

Nov 10
In all our excitement, we have forgotten that the Python wrapping of fastText only takes in a full file! We could of course build a Scikit pipeline that does all of the cleaning and training around the original data, and then build a script to do our own grid search. Ok, let's focus on building a data cleaning pipeline then, which includes grabbing the latest feedback from the database. That pipeline should be kicked off automatically, with cron or similar in another Docker.