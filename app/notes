# Redis: ~/Git_personal/MachineLearning/gutenberg/redis-stable/src/redis-server
# Minio: [start Docker] docker run -p 9000:9000 -e "MINIO_ACCESS_KEY=admin" -e "MINIO_SECRET_KEY=password" minio/minio:latest server /data
##
# Couchbase:
# username: admin
# password: password
# docker run -d --name db -p 8091-8096:8091-8096 -p 11210-11211:11210-11211 couchbase

# cbbackup http://localhost:8091 -u admin -p password /backup
# cbrestore /2018-10-08T052813Z/2018-10-08T052813Z-full/ http://localhost:8091 --bucket-source=feedback --bucket-destination=feedback -u admin -p password


Docker compose:
1. Couchbase
    - need to also include restore option for availability of views and so on - or, use the API to construct them during startup
2. Minio
3. Gutenberg itself
    - need a Docker container for it
    - what to do about the fastText dependencies?
    - need to move them out to another Docker container that just serves the model
4. fastText


-----------------------------------------------------

Now that we have set up Spark with Docker and are able to run some PySpark examples on it, we can even move the original training data into the Spark container.
However, that leaves us with a different problem, which is -- what to do with the feedback data? It needs to be moved into the Spark environment for us to really use it to train.

root@dac9157d87a8:/# couchbase-server -v
Couchbase Server 5.5.2-3733 (EE)

Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.3.1
      /_/

Using Python version 3.5.3 (default, Jan 19 2017 14:11:04)

Spark 2.3.x + Couchbase 5.5 = Connector 2.2.x
This is great, but right now there's only support for Scala and it will be hard to get this to work with CouchBase in PySpark. Here are some examples: https://github.com/couchbaselabs/couchbase-spark-samples/blob/master/src/main/scala/DatasetExample.scala.
This would be a great project to undertake when we're more comfortable with Scala and can move the Python training code into Scala.

For now, let's use Scikit Learn and Pipelines to re-train with the original data + feedback.
http://fizzylogic.nl/2017/11/07/learn-how-to-build-flexible-machine-learning-pipelines-in-sklearn/

It turns out that for Scikit you can write your own custom estimator (maybe we can also do a good grid search!) http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/

This seems simple enough. But why do you need to implement the "fit" method? It's not even in the BaseEstimator or the ClassifierMixin.

Nov 10
In all our excitement, we have forgotten that the Python wrapping of fastText only takes in a full file! We could of course build a Scikit pipeline that does all of the cleaning and training around the original data, and then build a script to do our own grid search. Ok, let's focus on building a data cleaning pipeline then, which includes grabbing the latest feedback from the database. That pipeline should be kicked off automatically, with cron or similar in another Docker.

Nov 27
Model retraining would only be useful if we can pass the retrainer the model ID that we are dealing with.
To do that, we need to also store the trained data file location or something - where can i get the data from? -- for each model.
We also need to write an actual retraining pipeline that takes in the entire list of models and does retraining for each.
Not just part of the data train stuff but a cron job.