{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validations to be done: \n",
    "1. Is the text in English?  (WIP - need to learn more RDF)  \n",
    "2. Is publish date present? (no publish date: inferring from birth/death)\n",
    "3. Is publish date > 0\n",
    "\n",
    "Data prep: \n",
    "1. Divide dates into buckets: 10, 50, 100 years\n",
    "2. Download data and store in files for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import re\n",
    "import codecs\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_map(file_path, file_num):\n",
    "    g = rdflib.Graph()\n",
    "    g.parse(file_path, 'rdf')\n",
    "#     # grab language\n",
    "#     lang_pred = rdflib.URIRef('http://purl.org/dc/terms/language')\n",
    "#     print(lang_pred)\n",
    "#     lang_obj = [i for i in g.objects(None, lang_pred)] \n",
    "#     print(lang_obj)\n",
    "#     lang = lang_obj[0] if len(lang_obj) > 0 else None\n",
    "#     print(lang)\n",
    "#     if (not lang or str(lang) is not 'en'):\n",
    "#         return None, None\n",
    "    # estimate publish date from author's birth/death\n",
    "    ## grab birth date\n",
    "    birth_pred = rdflib.URIRef('http://www.gutenberg.org/2009/pgterms/birthdate')\n",
    "    birth_obj = [i for i in g.objects(None, birth_pred)] \n",
    "    birth = birth_obj[0] if len(birth_obj) > 0 else None\n",
    "    #@ grab death date\n",
    "    death_pred = rdflib.URIRef('http://www.gutenberg.org/2009/pgterms/deathdate')\n",
    "    death_obj = [i for i in g.objects(None, death_pred)]\n",
    "    death = death_obj[0] if (len(death_obj) > 0 and birth is not None) else None\n",
    "    estimated_publish = None\n",
    "    ## estimate publish date\n",
    "    if death and birth: \n",
    "        estimated_publish = str((int(death) + int(birth)) / 2)\n",
    "    # grab uri for text\n",
    "    format_pred = rdflib.URIRef('http://purl.org/dc/terms/hasFormat')\n",
    "    subj = rdflib.URIRef('http://www.gutenberg.org/ebooks/{}'.format(file_num))\n",
    "    fmt_link = g.objects(subj, format_pred)\n",
    "    for i in fmt_link:\n",
    "        if 'txt' in i: #grab the first text url\n",
    "            return (str(i), estimated_publish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download_raw_text(url, output_path, max_content=50000, block_size=1024):\n",
    "    import requests\n",
    "    stream = requests.get(url, stream=True)\n",
    "    with open(output_path, 'wb') as fh: \n",
    "        count = 0\n",
    "        for block in stream.iter_content(block_size):\n",
    "            fh.write(block)\n",
    "            count += block_size\n",
    "            if count > max_content:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_raw_text(url_map, total_size):\n",
    "    print(\"Downloading raw text of size {0}\".format(total_size))\n",
    "    train_map = {}\n",
    "    count = 0\n",
    "    for idx, data in url_map.items():\n",
    "        if data:\n",
    "            url, publish = data\n",
    "            if publish: \n",
    "                count += 1\n",
    "                dl_path = idx+'.txt'\n",
    "                _download_raw_text(url, dl_path)\n",
    "                train_map[idx] = (dl_path, publish)\n",
    "    print(\"Total valid data = \" + str(count))\n",
    "    print(\"% valid of original data = \" + str(count/total_size))\n",
    "    return train_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_up(text):\n",
    "    text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _blob_text(file_path, read_start_line=80, byte_num=500): \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(file_path)\n",
    "    with(codecs.open(file_path, 'r', encoding='utf-8')) as fh: \n",
    "#         if len(list(fh)) < (read_start_line * 2):\n",
    "#             return None\n",
    "        line = None\n",
    "        count = 0\n",
    "        while count < read_start_line:\n",
    "            try: \n",
    "                fh.readline()\n",
    "            except:\n",
    "                # got tired of handling utf-8 issues\n",
    "                return None\n",
    "            count += 1\n",
    "        try:\n",
    "            data = fh.read(byte_num)\n",
    "        except:\n",
    "            # got tired of handling utf-8 issues\n",
    "            return None\n",
    "        return _clean_up(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_pub_label(pub_date, start_year=1500, end_year=2020, gap_years=20):\n",
    "    \"\"\"\n",
    "    given the start year, the end year, the gap_years \n",
    "    and the publish date, get the label\n",
    "    \"\"\"\n",
    "    if pub_date < start_year or pub_date > end_year: \n",
    "        print(\"publish date {0} is not between {1} and {2}\"\n",
    "                                       .format(pub_date, start_year, end_year))\n",
    "        return None\n",
    "    label = math.floor((pub_date - start_year) / gap_years) \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(output_file, data_map): \n",
    "    print(\"Formatting data for {0}\".format(output_file))\n",
    "    wr = codecs.open(output_file, 'w', encoding='utf-8')\n",
    "    count = 0\n",
    "    for idx,fle_dat in data_map.items(): \n",
    "        path, publish = fle_dat\n",
    "        text = _blob_text(path)\n",
    "        if text:\n",
    "            pub_label = _get_pub_label(float(publish))\n",
    "            if pub_label:\n",
    "                labeled_line = '__label__' + str(pub_label) + ',' + text + '\\n'\n",
    "                wr.write(labeled_line)\n",
    "                count += 1\n",
    "    print(\"Actual data sample size: \" + str(count))\n",
    "    wr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train and test\n",
    "import random, os\n",
    "INPUT_TRAIN_SIZE = 300\n",
    "INPUT_TEST_SIZE = 100\n",
    "path_prefix = '/Users/ssami/Documents/Personal/cache/epub'\n",
    "all_texts = os.listdir(path_prefix)\n",
    "random.shuffle(all_texts)\n",
    "sample_input_train = all_texts[:INPUT_TRAIN_SIZE]\n",
    "sample_input_test = all_texts[INPUT_TRAIN_SIZE+1:INPUT_TRAIN_SIZE+1+INPUT_TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_data(path_prefix, \n",
    "               sample_input_list, \n",
    "               size=INPUT_TRAIN_SIZE):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    file_map = {}\n",
    "    for i in sample_input_list: \n",
    "        file_path = os.path.join(path_prefix, i,'pg'+i+'.rdf')\n",
    "        file_map[i] = _create_map(file_path, i)\n",
    "    text_map = download_raw_text(file_map, size)    # raw map of publish date to text\n",
    "    return text_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading raw text of size 300\n",
      "Total valid data = 232\n",
      "% valid of original data = 0.7733333333333333\n"
     ]
    }
   ],
   "source": [
    "# build random training data\n",
    "train_map = build_data(path_prefix, sample_input_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting data for train.txt\n",
      "publish date 1480.5 is not between 1500 and 2020\n",
      "publish date 758.0 is not between 1500 and 2020\n",
      "publish date 1363.5 is not between 1500 and 2020\n",
      "Actual data sample size: 209\n"
     ]
    }
   ],
   "source": [
    "format_data('train.txt', train_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading raw text of size 100\n",
      "Total valid data = 74\n",
      "% valid of original data = 0.74\n",
      "Formatting data for test.txt\n",
      "Actual data sample size: 65\n"
     ]
    }
   ],
   "source": [
    "# build random testing data\n",
    "test_map = build_data(path_prefix, sample_input_test, INPUT_TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting data for test.txt\n",
      "publish date 730.0 is not between 1500 and 2020\n",
      "Actual data sample size: 64\n"
     ]
    }
   ],
   "source": [
    "format_data('test.txt', test_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
